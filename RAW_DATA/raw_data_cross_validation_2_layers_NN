import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, StratifiedKFold
import keras
from keras.models import Sequential, Model
from keras.layers import Input, Dense
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from sklearn.metrics import mean_absolute_error
from statistics import median
import timeit

# Set start time
start_time = timeit.default_timer()

# Load data
prk = pd.read_csv("https://raw.githubusercontent.com/veronique-ka/autoencoders_prk/master/prk_reord_bin.csv")

# Convert pandas dataframe to numpay array
p=np.array(prk)

x=p[:,1:20]
y=p[:,20]
        
#Standardize features by removing the mean and scaling to unit variance
from sklearn.preprocessing import StandardScaler
scale = StandardScaler()
x = scale.fit_transform(x)


#Initialise the lists of metrics, based on 10 iterations
MSE_10 = list()
R2_10 = list()
MAE_10 = list()

# initialise 10 itereations for K-folds partitions
for i in range(0,10):

    # Define k-fold validation splits
    def load_data_kfold(k):              

        folds = list(StratifiedKFold(n_splits=k, shuffle=True).split(x, y))
        
        return folds, x, y
    
    k = 10
    folds, x, y = load_data_kfold(k)
    
    # 2 layers 20-5 NN model
    def get_model():
        
        model=Sequential()
        model.add(Dense(20,input_dim=19,activation="sigmoid"))
        model.add(Dense(5,init="normal",activation="sigmoid"))
        model.add(Dense(1,init='normal', activation="linear"))
        model.compile(loss='mse', optimizer='sgd')       
         
        return model
    
    model = get_model()
    model.summary()
    
    # initiate lists of metrics based on individual fold's metrics
    MSE_valid_folds = list()
    R2_valid_folds = list()
    MAE_valid_folds = list()
    
    # initiate partitions into train and validation subsets
    for j, (train_idx, val_idx) in enumerate(folds):
            
            print('\nFold ',j)
            x_train_cv = x[train_idx]
            y_train_cv = y[train_idx]
            x_valid_cv = x[val_idx]
            y_valid_cv= y[val_idx]
            
            # Train the model for each partition
            model = get_model()
            model.fit(x_train_cv,y_train_cv, 
                        batch_size=64, 
                        nb_epoch=200, 
                        verbose=1,
                        shuffle=True,
                        validation_data = (x_valid_cv, y_valid_cv))
                        
            # Predict values for each k-validation subset
            valid_predictions=model.predict(x_valid_cv)
            
            # Get metrics' values for each fold and append them in 10-dim array (10 folds)
            MSE_valid_folds.append(mean_squared_error(y_valid_cv, valid_predictions))
            R2_valid_folds.append(r2_score(y_valid_cv, valid_predictions))
            MAE_valid_folds.append(mean_absolute_error(y_valid_cv,valid_predictions))
     
    print("MSE_valid =", MSE_valid_folds)
    print("R2_valid=", R2_valid_folds) 
    print("MAE_valid=", MAE_valid_folds)
    
    # Calculate median-average of metrics from 10 folds and append to the 10-dim array (10 trials)
    MSE_10.append(median(MSE_valid_folds))
    R2_10.append(median(R2_valid_folds))
    MAE_10.append(median(MAE_valid_folds))

print("MSE_10 =", MSE_10)
print("R2_10 =", R2_10) 
print("MAE_10=", MAE_10) 
   
# Calculate median-average of metrics from 10 trials 
MSE_final=median(MSE_10)
print(MSE_final)
R2_final=median(R2_10)
print(R2_final)
MAE_final=median(MAE_10)
print(MAE_final)

# Calculate total time of algorithm running
end_time = timeit.default_timer()
hours, rem = divmod(end_time-start_time, 3600)
minutes, seconds = divmod(rem, 60)
print ("{:0>2}:{:0>2}:{:05.2f}".format(int(hours),int(minutes),seconds))
