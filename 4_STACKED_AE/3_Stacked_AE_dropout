import timeit
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from keras.layers import Input, Dense
from keras.models import Model
from keras.models import Sequential
from keras.optimizers import SGD
from keras.layers import Dropout
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from sklearn.metrics import mean_absolute_error
from statistics import median

# Set start time
start_time = timeit.default_timer()

# Load data
prk = pd.read_csv("https://raw.githubusercontent.com/veronique-ka/autoencoders_prk/master/prk_reord_bin.csv")

#Convert pandas dataframe to numpay array
p=np.array(prk)

# Initiate lists of metrics, based on 10 iterations (trials)
MSE_test_10 = list()
R2_test_10 = list()
MAE_test_10 =list()

for i in range(0,10):
    #split into train and test
    print("Partition number=", i)
    split = train_test_split(p, test_size=0.3)
    train=split[0]
    test=split[1]
    x_train=train[:,1:20]
    y_train=train[:,20]
    x_test=test[:,1:20]
    y_test=test[:,20]
    
    # Normalize values between 0 and 1 and
    min_max=MinMaxScaler()
    x_train=min_max.fit_transform(x_train)
    x_test=min_max.fit_transform(x_test)

          
    # Start Layer-wise pretraining
    
    # Initiate list of separate deep Encoder
    encoders = []
    
    # Define architecture
    nb_hidden_layers = [19,30,20,10,3]
    # Copy data to temporary datasets 
    x_train_tmp = np.copy(x_train)
    x_test_tmp = np.copy(x_test)
    
    # Start layer-wise training by interacting each pair of layers within a deep structure 
    for j, (n_in, n_out) in enumerate(zip(nb_hidden_layers[:-1], nb_hidden_layers[1:]), start=1):
        # Print numbers of layers being trained
        print('Training the layer {}: Input {} -> Output {}'.format(j, n_in, n_out))  
    
        # Create vanilla AE between each pair of layers        
        inputs = Input(shape=(n_in,))
        #Introduce dropout constraint
        encoded = Dropout(0.2)
        encoded = Dense(n_out, activation='sigmoid')(inputs)
        decoded = Dense(n_in, activation='sigmoid')(encoded)
        autoencoder = Model(inputs, decoded)
        autoencoder.summary()

        # Compile AE
        autoencoder.compile(loss='binary_crossentropy', optimizer='adam')
        
        # Train AE to reconstruct
        autoencoder.fit(x_train_tmp, x_train_tmp, batch_size=64, nb_epoch=200, validation_data=(x_test_tmp, x_test_tmp))
        
        # Store trainined weights and update training data
        encoders.append(autoencoder.layers[0])
        
        # Get a separate model of Encoder
        encoder = Model(inputs, encoded)
        
        # Get a code or encoded representation in a pair of layers
        encoded_train=encoder.predict(x_train_tmp)
        encoded_test=encoder.predict(x_test_tmp)
        
        # Assign encoded representation to the input for the next layer to start loop again
        x_train_tmp = encoded_train 
        x_test_tmp = encoded_test
             
        
    # Fine-turning
    model = Sequential()
    # Get a sequense of all pre-trained encoders into a deep structure
    for encoder in encoders:
        model.add(encoder)
    # Add supervised model by attaching 20-NN where input is a product of training Deep structure
    model.add(Dense(nb_hidden_layers[-1], activation='sigmoid'))
    # Introduce droput constraint    
    model.add(Dense(20, activation="sigmoid"))
    model.add( Dropout(0.2))
    model.add(Dense(1, activation="linear"))
    model.compile(loss='mse', optimizer="sgd")
    
    model.summary()
    
    # Train model
    history=model.fit(x_train, y_train, batch_size=64, nb_epoch=200, validation_data=(x_test, y_test))
    
    # Visualize training process
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper left')
    plt.show()

        
    # Get predictions on the test-set by the entire structure
    test_predictions=model.predict(x_test)
    
    # Calculate Mean squarred error and append result to 10-dim array   
    MSE_test_10.append(mean_squared_error(y_test, test_predictions))
    print("MSE_test_10 =", MSE_test_10)
    
    # Calculate R2 and append result to 10-dim array   
    R2_test_10.append(r2_score(y_test, test_predictions))
    print("R2_test_10 =", R2_test_10)

    # Calculate Mean absolute error and append to 10-dim array
    MAE_test_10.append(mean_absolute_error(y_test,test_predictions))
    print("MAE_test_10", MAE_test_10)

#Calculate median of 10 trials
MSE_final=median(MSE_test_10)
R2_final=median(R2_test_10)
MAE_final=median(MAE_test_10)
print("MSE_final=", MSE_final)
print("R2_final=", R2_final)
print("MAE_final=", MAE_final)

#Set end time to calculate total time of code running
end_time = timeit.default_timer()
hours, rem = divmod(end_time-start_time, 3600)
minutes, seconds = divmod(rem, 60)
print ("{:0>2}:{:0>2}:{:05.2f}".format(int(hours),int(minutes),seconds))
